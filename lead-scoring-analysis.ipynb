{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d624256c-8de6-46b2-acc2-41fcd5220699",
   "metadata": {},
   "source": [
    "# Modelo de Lead Scoring\n",
    "\n",
    "En este notebook iremos desarrollando las tareas necesarias para construir un modelo de lead scoring comenzando desde la ingesta de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d0860-1077-4d87-a7bf-8a388a4001b5",
   "metadata": {},
   "source": [
    "## 1. Data analysis\n",
    "\n",
    "Importamos todas las librerias necesarias y consumimos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1607b2-4af6-4555-82eb-42bc4ee7513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(rc={'figure.figsize':(21.7,21.27)})\n",
    "pd.options.display.max_columns = None\n",
    "data = pd.read_csv('./leads/Leads.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8432d52b-394c-4306-bfc4-37c7528e081f",
   "metadata": {},
   "source": [
    "### 1.1 Data Cleaning\n",
    "\n",
    "En esta etapa nos familiarizamos con los datos e intentamos entender que tipo de informacion aporta cada variable. De aqui surgiran hipotesis respecto a que variables son mas relevantes y que tipo de limpieza/curacion sera necesaria\n",
    "\n",
    "Empezamos desplegando las primeras 5 filas para entender que cosas trae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0352142-b572-4334-a9b6-a8ea0651aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58aad84-dc95-4bc6-9304-f19d24677e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973850c-e1cf-477c-bfe3-ba6b10017e5b",
   "metadata": {},
   "source": [
    "Notamos:\n",
    "\n",
    "- Hay algunos campos con valores nulos\n",
    "- Hay un campo \"booleano\" (converted), que es el que probablemente querramos predecir\n",
    "- Empezamos a intuir los valores que puede tomar cada columna\n",
    "\n",
    "Ahora nos falta entender mejor los campos no numericos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e891ba-4f02-4574-b10c-cb2a0c3fcf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d47ed7c-1f03-4fcc-a2d9-807257644e49",
   "metadata": {},
   "source": [
    "Notamos:\n",
    "\n",
    "- Hay campos identificadores que podriamos excluir del modelo (`prospect id`, `lead Number`)\n",
    "- Hay campos que unicamente tienen un valor (`Magazine` ,`I agree to pay the amount through cheque`, `Receive more updates` , etc) que podriamos excluir por no agregar info\n",
    "- Hay algunos campos que podriamos procesar un poco para que representen mejor su informacion (Campos de `Asymmetrique`)\n",
    "- Hay mas campos \"booleanos\" codificados como texto (`Do not Email`, `Do not call`)\n",
    "\n",
    "Ya que notamos que hay valores nulos, veamos cuantos hay en cada columna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae002465-d3d0-40c8-a44a-848112067fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b41ee2-1ac8-4561-9a33-ba192d29168a",
   "metadata": {},
   "source": [
    "Vemos que hay muchas columnas con valores nulos. Y muchos de ellas con casi el 50% de sus valores asi. Vamos a deshacernos de ellas y de las otras columnas que identificamos y a convertir las columnas booleanas a numerica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ab973e-fd12-437a-984a-220de4b93cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis=1)\n",
    "data = data.drop(columns=['Prospect ID', 'Lead Number', 'I agree to pay the amount through cheque', 'Magazine', 'Receive More Updates About Our Courses', \n",
    "                          'Update me on Supply Chain Content', 'Get updates on DM Content' ])\n",
    "string_to_boolean_map = {\"Yes\": 1, \"No\": 0}\n",
    "for column in data.columns:\n",
    "    if 'Yes' in data[column].values and 'No' in data[column].values:\n",
    "        data[column] = data[column].map(string_to_boolean_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875aaf58-92d8-40ec-944f-699c3a8fc684",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412c08b-a4bc-4f7c-bca9-d274badabef9",
   "metadata": {},
   "source": [
    "Luego de haber *limpiado* nuestros datos, estamos en conndiciones de comenzar la **exploracion** en busqueda de relaciones interesantes entre nuestras variables\n",
    "\n",
    "### 1.2 Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f085486-3fb7-43e1-8457-04603b599526",
   "metadata": {},
   "source": [
    "Comenzamos graficando algunas de las variables respecto a nuestra variable **a predecir**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ce1e3-0e09-4859-b491-5ebedc1e1ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=data, y='Converted', x='Lead Origin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7fd278-4809-4127-98ae-8ed816ec6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=data, y='Converted', x='Do Not Email')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd81ed-707c-44bf-b6ce-7741cb93eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=data, y='Converted', x='Search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d1137-b5fb-4525-83fa-a6c7bf76e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=data, y='Converted', x='Last Notable Activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ebdb3-3e3c-4010-ac9e-e0c45020404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=data, x='Total Time Spent on Website')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c94582-3d3e-4641-8db5-ebde870c36c6",
   "metadata": {},
   "source": [
    "## 2. Model Building\n",
    "\n",
    "Ahora que hemos explorado los datos y tenemos una mejor idea de como se relacionan con la variable a predecir, comenzaremos a construir modelos tentativos para predecir la conversion\n",
    "\n",
    "Comenzamos dandole un ultimo pre-procesamiento a nuestros datos antes de que puedan usarse de input para los modelos. Hay que convertir las variables categoricas (`Last Notable Activity` y `Lead Origin`) a algo sobre lo que se pueda operar matematicamente. Utilizaremos **one-hot encoding** para lograrlo. Pandas provee una forma sencilla de aplicar esta transformacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce70755-45e6-42d1-864e-1020667ca051",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_variables = pd.get_dummies(data[['Lead Origin', 'Last Notable Activity']], drop_first=True)\n",
    "data = pd.concat([data, one_hot_encoded_variables], axis=1)\n",
    "data = data.drop(['Lead Origin', 'Last Notable Activity'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad68ae-599e-448a-9645-791a4ac22ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc99e4e-82c9-4df4-bf7b-3dac80a6a884",
   "metadata": {},
   "source": [
    "### 2.1 Creacion de datasets de entrenamiento y de prueba\n",
    "\n",
    "Ahora debemos separar la **variable a predecir** del resto de los **predictores**, asi como separar nuestros datos en datasets de **entrenamiento** y **prueba** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd8485-2ee9-45a7-b59f-cfab2dffc450",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = data.drop(['Converted'], axis=1)\n",
    "to_predict = data['Converted'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, to_predict, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185b3124-de2d-4d29-8947-e877a59dc265",
   "metadata": {},
   "source": [
    "### 2.2 Feature Scaling\n",
    "\n",
    "Todas las variables predictoras, a excepcion del tiempo total de visita al sitio web, son booleanas (sus valores pueden ser 0 o 1). Para que el modelo no se sesgue con esa otra variable, conviene aplicar algun tipo de escalado (en nuestro caso, **estandarizacion**) sobre esa variable para convertir sus valores a una unidad \"estandar\" compartida por todas las demas (en este caso, la \"desviacion estandar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b6344-b816-4efe-b9ea-5e5b32e5703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train['Total Time Spent on Website'] = scaler.fit_transform(X_train[['Total Time Spent on Website']])\n",
    "X_test['Total Time Spent on Website'] = scaler.fit_transform(X_test[['Total Time Spent on Website']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05030e-0449-479c-b255-03491f925918",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f408a7-e8b1-455c-9ee6-91711dba71ae",
   "metadata": {},
   "source": [
    "### 2.3 Model Fitting\n",
    "\n",
    "En esta etapa entrenaremos los diferentes modelos que creemos mas adecuados para el problema\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6efce7-02ce-4890-bd1d-467c8fdebc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression_model = LogisticRegression().fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364da3ea-9554-4e0f-bfa1-89ff17ed339a",
   "metadata": {},
   "source": [
    "### 2.4 Evaluacion de la calidad del modelo\n",
    "\n",
    "La calidad de la estimacion en el dataset de **prueba** es\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e35498-532f-4290-baf0-da468bf54e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61cc9b8-19c0-4632-bde3-3a10777bda25",
   "metadata": {},
   "source": [
    "Y en el de **entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e1597-6c67-44c0-95e4-eda2638d982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf1a39-9245-49b0-81d3-05237a7a44a7",
   "metadata": {},
   "source": [
    "Realizamos la **matriz de confusion** y obtenemos las metricas asociadas a estos valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31521b4a-e500-4465-ab09-13f5f97445f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, logistic_regression_model.predict(X_test))).plot(cmap=\"YlOrRd\")\n",
    "print(classification_report(y_test, logistic_regression_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2899160d-4b75-46e4-ab9f-3d1fd0f4b89d",
   "metadata": {},
   "source": [
    "## Probando una Red neuronal\n",
    "\n",
    "Como modelo competidor, probamos entenar una red neuronal (Perceptron multicapa) y evaluamos su desempeno respecto a la regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770782e-da72-44db-9e7f-bee3107e78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data = X_train.values\n",
    "dimensions = formatted_data.shape\n",
    "\n",
    "adam_optimizer = Adam(learning_rate=0.01)\n",
    "neural_net = Sequential()\n",
    "neural_net.add(Dense(128, input_dim=dimensions[1], activation='tanh'))\n",
    "neural_net.add(Dense(256, input_dim=dimensions[1], activation='tanh'))\n",
    "neural_net.add(Dense(128, input_dim=dimensions[1], activation='tanh'))\n",
    "neural_net.add(Dense(1, activation='sigmoid'))\n",
    "neural_net.compile(loss='binary_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])\n",
    "neural_net.fit(formatted_data, y_train.values, epochs=100, batch_size=1000, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66a372-e68d-4886-af36-00654ab613e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_test.values, neural_net.predict_classes(X_test.values))).plot(cmap=\"YlOrRd\")\n",
    "print(classification_report(y_test.values, neural_net.predict_classes(X_test.values)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
